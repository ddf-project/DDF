package io.spark.ddf.util

import java.util.{Map â‡’ JMap}
import scala.collection.JavaConverters._
import shark.{KryoRegistrator, SharkContext}
import org.apache.spark.SparkConf

/**
  */

object SparkUtils {
  /**
   * Create custom sharkContext with adatao's spark.kryo.registrator
   * @param master
   * @param jobName
   * @param sparkHome
   * @param jars
   * @param environment
   * @return
   */
  def createSparkConf(master: String, jobName: String, sparkHome: String, jars: Array[String],
                      environment: JMap[String, String]): SparkConf = {
    val conf = SharkContext.createSparkConf(master, jobName, sparkHome, jars, environment.asScala)

    conf.set("spark.kryo.registrator", System.getProperty("spark.kryo.registrator", "io.spark.content.KryoRegistrator"))
  }

  def createSharkContext(master: String, jobName: String, sparkHome: String, jars: Array[String],
                         environment: JMap[String, String]): SharkContext = {
    val conf = createSparkConf(master, jobName, sparkHome, jars, environment)
    new SharkContext(conf)
  }
}
