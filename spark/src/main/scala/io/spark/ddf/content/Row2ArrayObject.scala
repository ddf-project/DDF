package io.spark.ddf.content

import org.apache.spark.rdd.RDD
import shark.api.Row
import io.ddf.content.{ Representation, ConvertFunction }
import io.ddf.DDF

/**
 */
class Row2ArrayObject(@transient ddf: DDF) extends ConvertFunction(ddf) {

	override def apply(representation: Representation): Representation = {
		val rdd = representation.getValue.asInstanceOf[RDD[Row]]
		val rddArrObj = rdd.map {
			row â‡’
				{
					val size = row.rawdata.asInstanceOf[Array[Object]].size
					val array = new Array[Object](size)
					var idx = 0
					while (idx < size) {
						array(idx) = row.getPrimitive(idx)
						idx += 1
					}
					array
				}
		}
		new Representation(rddArrObj, RepresentationHandler.RDD_ARR_OBJECT.getTypeSpecsString)
	}
}
