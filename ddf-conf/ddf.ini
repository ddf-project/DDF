[global]
; The default name space used to uniquely address DDF's in storage, sharing, collaboration, etc.
Namespace = adatao
; The directory in which to save run-time data, e.g., the basic-persistence database
RuntimeDir = ddf-runtime
; The basic-persistence database directory, just below runtime/
BasicPersistenceDir = basic-ddf-db
DDF = io.ddf.DDF
DDFManager = io.ddf.DDFManager
ISupportStatistics = io.ddf.analytics.AStatisticsSupporter
IHandleAggregation = io.ddf.analytics.AggregationHandler
IHandleMetaData = io.ddf.content.MetaDataHandler
IHandleRepresentations = io.ddf.content.RepresentationHandler
IHandleSchema = io.ddf.content.SchemaHandler
IHandleViews = io.ddf.content.ViewHandler
IHandlePersistence = io.basic.ddf.content.PersistenceHandler
ISupportML = io.ddf.ml.MLSupporter
ISupportMLMetrics = io.ddf.spark.ml.MLMetricsSupporter
IHandleTransformations = io.ddf.etl.TransformationHandler
IHandleMutability = io.ddf.content.MutabilityHandler
IHandleMissingData = io.ddf.etl.MissingDataHandler
;IHandleTimeSeries = io.ddf.etl.TimeSeriesHandler
;IHandleSql = io.ddf.etl.SqlHandler
;IRunAlgorithms = io.ddf.analytics.AlgorithmRunner
MAX_LEVELS_COUNT = 10000
MAX_NUMBER_OF_DDFS_IN_CACHE = 4000
MAX_NUMBER_OF_DDFS_WITH_NAME_IN_CACHE = 500
DDF_TIME_TO_IDLE_SECONDS = 43200

[spark]
DDF = io.ddf.spark.SparkDDF
DDFManager = io.ddf.spark.SparkDDFManager
Model = io.ddf.spark.ml.Model
DefaultEngineContainerType = "org.apache.spark.rdd.RDD"
ISupportStatistics = io.ddf.spark.analytics.BasicStatisticsComputer
IHandleAggregation = io.ddf.spark.analytics.AggregationHandler
IHandleMetaData = io.ddf.spark.content.MetaDataHandler
IHandleRepresentations = io.ddf.spark.content.RepresentationHandler
IHandleSchema = io.ddf.spark.content.SchemaHandler
IHandleSql = io.ddf.spark.etl.SqlHandler
IHandleViews = io.ddf.spark.content.ViewHandler
IHandleJoins = io.ddf.spark.etl.JoinHandler
ISupportML = io.ddf.spark.ml.MLSupporter
IHandleTransformations = io.ddf.spark.etl.TransformationHandler
ISupportMLMetrics = io.ddf.spark.ml.MLMetricsSupporter
IHandleBinning = io.ddf.spark.analytics.BinningHandler
IHandleMutability = io.ddf.content.MutabilityHandler
IHandleMissingData = io.ddf.etl.MissingDataHandler
IHandleTimeSeries = io.ddf.spark.etl.TimeSeriesHandler
IHandlePersistence = io.ddf.spark.content.PersistenceHandler
kmeans = org.apache.spark.mllib.clustering.KMeans
linearRegressionLasso = org.apache.spark.mllib.regression.LassoWithSGD
linearRegressionWithSGD = org.apache.spark.mllib.regression.LinearRegressionWithSGD
logisticRegressionWithSGD = org.apache.spark.mllib.classification.LogisticRegressionWithSGD
svmWithSGD = org.apache.spark.mllib.classification.SVMWithSGD
collaborativeFiltering = org.apache.spark.mllib.recommendation.ALS
MAX_SAMPLE_SIZE = 1000000

[basic]
DDF = io.basic.ddf.BasicDDF
DDFManager = io.basic.ddf.BasicDDFManager

[jdbc]
DDF = io.ddf.jdbc.JDBCDDF
DDFManager = io.ddf.jdbc.JDBCDDFManager
IHandleSql = io.ddf.jdbc.etl.SqlHandler
Driver = com.mysql.jdbc.Driver
DDFAutoCreate = true

[sfdc]
Driver = cdata.jdbc.salesforce.SalesforceDriver
DDF = io.ddf.jdbc.JDBCDDF
DDFManager = io.ddf.jdbc.JDBCDDFManager
IHandleSql = io.ddf.sfdc.etl.SqlHandler
DDFAutoCreate = true
IHandleRepresentations = io.ddf.content.RepresentationHandler
IHandleSchema = io.ddf.content.SchemaHandler
IHandleMetaData = com.adatao.ddf.spark.content.MetaDataHandler

[s3]
DDFManager = io.ddf.s3.S3DDFManager
DDF = io.ddf.s3.S3DDF

[hdfs]
DDFManager = io.ddf.hdfs.HDFSDDFManager
DDF = io.ddf.hdfs.HDFSDDF
